{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# General Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import os\n",
    "import re\n",
    "# import multiprocessing\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().magic('matplotlib inline')\n",
    "plt.rcParams['figure.figsize'] = (16, 8)\n",
    "import scikitplot as skplt\n",
    "\n",
    "# Supervised Machine Learning Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron, SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import feature_selection\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier # <3\n",
    "\n",
    "# Unsupervised Models\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Evalaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "\n",
    "# Grid\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import scipy.stats as st\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Esemble Voting\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Stacking\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import platform\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Version      :', platform.python_version())\n",
    "print('Compiler     :', platform.python_compiler())\n",
    "print('Build        :', platform.python_build())\n",
    "\n",
    "print(\"\\nCurrent date and time using isoformat:\")\n",
    "print(datetime.datetime.now().isoformat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Master Parameters:\n",
    "n_splits = 5 # Cross Validation Splits\n",
    "n_iter = 65 # Randomized Search Iterations\n",
    "scoring = 'accuracy' # Model Selection during Cross-Validation\n",
    "rstate = 25 # Random State used \n",
    "testset_size = 0.30\n",
    "\n",
    "# Trees Parameters\n",
    "n_tree_range = st.randint(600, 1200)\n",
    "\n",
    "# XGboost boosting rounds\n",
    "num_rounds = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C:\\\\Users\\\\10335\\\\Downloads\\\\Default_Prediction_Research-master')\n",
    "os.listdir(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load\n",
    "df = pd.read_csv('data.csv')\n",
    "# For Pre-Processing, combine train/test to simultaneously apply transformations\n",
    "Target = df['Target'].copy()\n",
    "traindex = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Depedent and Indepedent Variables\n",
    "X = df.drop([\"Target\"] , axis=1)\n",
    "y = df[\"Target\"]\n",
    "print(\"X, Y:\",X.shape, y.shape) # Data Dimensions\n",
    "\n",
    "# Storage for Model and Results\n",
    "results = pd.DataFrame(columns=['Model','Para','Test_Score','CV Mean','CV STDEV'])\n",
    "ensemble_models= {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalanced Dependent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Depedent Variable Distribution\")\n",
    "print(y.value_counts(normalize=True)*100)\n",
    "print(\"0 = Insolvent\", \"\\n1 = Solvent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction: Principal Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Feature Count (With One Hot Encoding):\", X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "levels = [2,4,6,8,10,12]\n",
    "for x in levels:\n",
    "    pca = PCA(n_components=x)\n",
    "    fit = pca.fit(df)\n",
    "\n",
    "    print((\"{} Components \\nExplained Variance: {}\\n\").format(x, fit.explained_variance_ratio_))\n",
    "    #print(fit.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Reduce Dimensionality\n",
    "pca = PCA(n_components=5)\n",
    "fit = pca.fit(X)\n",
    "\n",
    "sns.heatmap(pd.concat([pd.DataFrame(fit.transform(X)), Target],\n",
    "                      axis=1).corr(), annot=True, fmt=\".2f\")\n",
    "# Apply Reduction\n",
    "X = pd.DataFrame(fit.transform(X))\n",
    "No longer applied to dataset since performance did not get substancially improved.\n",
    "Better just use method at an individual basis, through the pipeline method.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stratified Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testset_size, stratify=y,random_state=rstate)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape\n",
    "\n",
    "# Stratified Cross-Validation\n",
    "cv = StratifiedShuffleSplit(n_splits=n_splits, test_size=0.2, random_state=rstate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute, Print, and Save Model Evaluation\n",
    "def save(model, modelname):\n",
    "    \"\"\"\n",
    "    This funciton saves the cross-validated and test set evaluation value and standard deviation\n",
    "    to the results dataframe, then it executes the model prediction on the submission set.\n",
    "    Finally, it also outputs a confusion matrix of the test set.\n",
    "    \n",
    "    Arguments:\n",
    "    model = The Sklearn Randomized/Grid SearchCV model.\n",
    "    modelname = String of the model name for saving purposes.\n",
    "    \"\"\"\n",
    "    global results\n",
    "    # Once best model is found, establish more evaluation metrics.\n",
    "    model.best_estimator_.fit(X_train, y_train)\n",
    "    \n",
    "    # submission = model.predict(test_df)\n",
    "    # df = pd.DataFrame({'PassengerId':test_df.index,'Survived':submission})\n",
    "    # path = ...\n",
    "    # df.to_csv((os.path.join(path,(\"submissions/{}.csv\".format(modelname)))),header=True,index=False)\n",
    "    \n",
    "    scores = cross_val_score(model.best_estimator_, X_train, y_train, cv=5,\n",
    "                             scoring=scoring, verbose =0)\n",
    "    CV_scores = scores.mean()\n",
    "    STDev = scores.std()\n",
    "    Test_scores = model.score(X_test, y_test)\n",
    "\n",
    "    # CV and Save scores\n",
    "    results = results.append({'Model': modelname,'Para': model.best_params_,'Test_Score': Test_scores,\n",
    "                             'CV Mean':CV_scores, 'CV STDEV': STDev}, ignore_index=True)\n",
    "    ensemble_models[modelname] = model.best_estimator_\n",
    "    \n",
    "    # Print Evaluation\n",
    "    print(\"\\nEvaluation Method: {}\".format(scoring))\n",
    "    print(\"Optimal Model Parameters: {}\".format(grid.best_params_))\n",
    "    print(\"Train CV Accuracy: %0.2f (+/- %0.2f) [%s]\" % (CV_scores, STDev, modelname))\n",
    "    print('Test_Score:', Test_scores)\n",
    "        \n",
    "    # Scikit Confusion Matrix\n",
    "    model.best_estimator_.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    skplt.metrics.plot_confusion_matrix(y_test, pred, title=\"{} Confusion Matrix\".format(modelname),\n",
    "                normalize=True,figsize=(6,6),text_fontsize='large')\n",
    "    plt.show()\n",
    "    # Colors https://matplotlib.org/examples/color/colormaps_reference.html\n",
    "\n",
    "def norm_save(model,score, modelname):\n",
    "    global results\n",
    "    model.fit(X, y)\n",
    "    submission = model.predict(test_df)\n",
    "    df = pd.DataFrame({'Company.Name':test_df.index, \n",
    "                           'Target':submission})\n",
    "    \n",
    "    CV_Score = score.mean()\n",
    "    Test_scores = model.score(X_test, y_test)\n",
    "    STDev = score.std()\n",
    "    \n",
    "    # CV and Save Scores\n",
    "    Test_Score = model.score(X_test, y_test)\n",
    "    results = results.append({'Model': modelname,'Para': model,'Test_Score': Test_scores,\n",
    "                             'CV Mean': CV_Score, 'CV STDEV': STDev}, ignore_index=True)\n",
    "    ensemble_models[modelname] = model\n",
    "    \n",
    "    print(\"\\nEvaluation Method: {}\".format(scoring))\n",
    "    print(\"Train CV Accuracy: %0.2f (+/- %0.2f) [%s]\" % (CV_Score, STDev, modelname))  \n",
    "    print('Test_Score:', Test_scores)\n",
    "        \n",
    "    #Scikit Confusion Matrix\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    skplt.metrics.plot_confusion_matrix(y_test, pred, title=\"{} Confusion Matrix\".format(modelname),\n",
    "                normalize=True,figsize=(6,6),text_fontsize='large')\n",
    "    plt.show()\n",
    "    \n",
    "# ROC Curve Plot\n",
    "# http://scikit-plot.readthedocs.io/en/stable/metrics.html\n",
    "def eval_plot(model):\n",
    "    skplt.metrics.plot_roc_curve(y_test, model.predict_proba(X_test))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyper parameters. Since RandomizedSearchCV is used, I use an uniform random interger range for the function to choose from.\n",
    "param_grid ={'n_neighbors': st.randint(1,40),\n",
    "             # Increasing this value reduces bias, and increases variance. Don't Overfit!\n",
    "            'weights':['uniform','distance']\n",
    "            }\n",
    "# Hyper-Parameter Tuning with Cross-Validation\n",
    "grid = RandomizedSearchCV(KNeighborsClassifier(),\n",
    "                    param_grid, # Hyper Parameters\n",
    "                    cv=cv, # Cross-Validation splits. Stratified.\n",
    "                    scoring=scoring, # Best-Validation selection metric.\n",
    "                    verbose=1, # Quality of Life. Frequency of model updates\n",
    "                    n_iter=n_iter, # Number of hyperparameter combinations tried.\n",
    "                    random_state=rstate) # Reproducibility \n",
    "\n",
    "# Execute Tuning on entire dataset\n",
    "grid.fit(X_train, y_train)\n",
    "save(grid, \"KNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SGDClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid ={'loss':[\"hinge\",\"log\",\"modified_huber\",\"epsilon_insensitive\",\"squared_epsilon_insensitive\"]\n",
    "            }\n",
    "\n",
    "grid = GridSearchCV(SGDClassifier(),\n",
    "                    param_grid,cv=cv, scoring=scoring,\n",
    "                    verbose=1)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "save(grid, \"StochasticGradientDescent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper Function to visualize feature importance\n",
    "predictors = [x for x in X.columns if x not in ['Target']]\n",
    "def feature_imp(model):\n",
    "    MO = model.fit(X_train, y_train)\n",
    "    feat_imp = pd.Series(MO.feature_importances_, predictors).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DecisionTreeClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance Graphic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Baseline Decision Tree\n",
    "tree = DecisionTreeClassifier()\n",
    "print(\"Mean CV Accuracy:\",cross_val_score(tree, X, y, cv=cv, scoring=scoring).mean())\n",
    "feature_imp(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap aggregating (AKA Bagging) Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameter Tuning\n",
    "param_grid ={'n_estimators': n_tree_range}\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "grid = RandomizedSearchCV(BaggingClassifier(tree),\n",
    "                    param_grid, cv=cv, scoring=scoring,\n",
    "                    verbose=1,n_iter=n_iter, random_state=rstate)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "save(grid, \"Bagger_ensemble\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "print(\"Mean CV Accuracy:\",cross_val_score(model, X, y, cv=cv, scoring=scoring).mean())\n",
    "feature_imp(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RandomForestClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid ={'max_depth': st.randint(6, 11),\n",
    "             'n_estimators': n_tree_range,\n",
    "             'max_features':np.arange(0.5,.81, 0.05),\n",
    "            'max_leaf_nodes':st.randint(6, 10)}\n",
    "\n",
    "model= RandomForestClassifier()\n",
    "\n",
    "grid = RandomizedSearchCV(model,\n",
    "                    param_grid, cv=cv,\n",
    "                    scoring=scoring,\n",
    "                    verbose=1,n_iter=n_iter, random_state=rstate)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "save(grid, \"Random_Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_imp(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AdaBoostClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid ={'n_estimators':n_tree_range,\n",
    "            'learning_rate':np.arange(.1, 4, .5)}\n",
    "\n",
    "grid = RandomizedSearchCV(AdaBoostClassifier(),\n",
    "                    param_grid,cv=cv, scoring=scoring,\n",
    "                    verbose=1, n_iter=n_iter, random_state=rstate)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "save(grid, \"AdaBoost_Ensemble\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_imp(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GradientBoostingClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid ={'n_estimators': n_tree_range,\n",
    "            'loss': ['deviance', 'exponential'],\n",
    "            'learning_rate':np.arange(0.01, 0.32,.05),\n",
    "            'max_depth': np.arange(2, 4.1, .5)}\n",
    "\n",
    "grid = RandomizedSearchCV(GradientBoostingClassifier(),\n",
    "                    param_grid,cv=cv,\n",
    "                    scoring=scoring,\n",
    "                    verbose=1, n_iter=n_iter, random_state=rstate)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "save(grid, \"Gradient_Boosting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_imp(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost - eXtreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XGBClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_to_left = st.beta(10, 1)  \n",
    "from_zero_positive = st.expon(0, 50)\n",
    "\n",
    "params = {  \n",
    "    \"n_estimators\": n_tree_range,\n",
    "    \"max_depth\": st.randint(2, 8),\n",
    "    \"learning_rate\": [0.01],\n",
    "    #'max_features':'sqrt',\n",
    "    #\"learning_rate\": st.uniform(0.001, 0.1),\n",
    "    \"colsample_bytree\": one_to_left,\n",
    "    \"subsample\": one_to_left,\n",
    "    \"gamma\": st.uniform(0, 3),\n",
    "    #'reg_alpha': from_zero_positive,\n",
    "    #\"min_child_weight\": from_zero_positive,\n",
    "    'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05]\n",
    "}\n",
    "\n",
    "xgbreg = XGBClassifier(objective= 'binary:logistic', eval_metric=\"auc\",\n",
    "                       nthreads=2)\n",
    "\n",
    "grid = RandomizedSearchCV(xgbreg, params, n_jobs=1, verbose=1, n_iter=n_iter,\n",
    "                          random_state=rstate, scoring=scoring)  \n",
    "grid.fit(X_train,y_train, verbose=False)\n",
    "save(grid, \"Sci_kit XGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_imp(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = XGBClassifier(n_estimators = num_rounds,\n",
    "                        objective= 'binary:logistic',\n",
    "                     learning_rate=0.01, random_state=rstate, scoring=scoring)\n",
    "\n",
    "# use early_stopping_rounds to stop the cv when there is no score imporovement\n",
    "model.fit(X_train,y_train, early_stopping_rounds=20, eval_set=[(X_test,\n",
    "y_test)], verbose=False)\n",
    "score = cross_val_score(model, X_train,y_train, cv=cv)\n",
    "print(model)\n",
    "print(\"\\nxgBoost - CV Train : %.2f\" % score.mean())\n",
    "print(\"xgBoost - Train : %.2f\" % metrics.accuracy_score(model.predict(X_train), y_train))\n",
    "print(\"xgBoost - Test : %.2f\" % metrics.accuracy_score(model.predict(X_test), y_test))\n",
    "norm_save(model,score, \"XGBsklearn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Package Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "xgtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# set xgboost params\n",
    "param = {'max_depth': 3,  # the maximum depth of each tree\n",
    "         'objective': 'binary:logistic'}\n",
    "\n",
    "clf_xgb_cv = xgb.cv(param, xgtrain, num_rounds, \n",
    "                    stratified=True, \n",
    "                    nfold=n_splits, \n",
    "                    early_stopping_rounds=20)\n",
    "print(\"Optimal number of trees/estimators is %i\" % clf_xgb_cv.shape[0])\n",
    "\n",
    "watchlist  = [(xgtest,'test'), (xgtrain,'train')]                \n",
    "clf_xgb = xgb.train(param, xgtrain,clf_xgb_cv.shape[0], watchlist)\n",
    "\n",
    "# predict function will produce the probability \n",
    "# so we'll use 0.5 cutoff to convert probability to class label\n",
    "y_train_pred = (clf_xgb.predict(xgtrain, ntree_limit=clf_xgb.best_iteration) > 0.5).astype(int)\n",
    "y_test_pred = (clf_xgb.predict(xgtest, ntree_limit=clf_xgb.best_iteration) > 0.5).astype(int)\n",
    "score= metrics.accuracy_score(y_test_pred, y_test)\n",
    "print(\"\\nXGB - CV Train : %.2f\" % score)\n",
    "print(\"XGB - Train : %.2f\" % metrics.accuracy_score(y_train_pred, y_train))\n",
    "norm_save(model,score, \"XGBstandard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model= LogisticRegression()\n",
    "score = cross_val_score(model, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "norm_save(LogisticRegression(),score, \"Logistic_Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "logit = sm.Logit(y, X) # fit the model\n",
    "result = logit.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedforward Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MLPClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start with a RandomSearchCV to efficiently Narrow the Ballpark\n",
    "param_grid ={'max_iter': np.logspace(1, 5, 10).astype(\"int32\"),\n",
    "             'hidden_layer_sizes': np.logspace(2, 3, 4).astype(\"int32\"),\n",
    "             'activation':['identity', 'logistic', 'tanh', 'relu'],\n",
    "             'learning_rate': ['adaptive'],\n",
    "             'early_stopping': [True],\n",
    "             'alpha': np.logspace(2, 3, 4).astype(\"int32\")\n",
    "            }\n",
    "\n",
    "model = MLPClassifier()\n",
    "grid = RandomizedSearchCV(model,\n",
    "                    param_grid, cv=cv, scoring=scoring,\n",
    "                    verbose=1, n_iter=n_iter, random_state=rstate)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "save(grid, \"FFNeural_Net\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LinearSVC().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Model\n",
    "model = LinearSVC()\n",
    "\n",
    "#Fit Model\n",
    "scores= cross_val_score(model, X_train, y_train, cv=cv, scoring=scoring)\n",
    "norm_save(model, scores, \"LinearSV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radial Basis Function (RBF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVC().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc = SVC(kernel= 'rbf', probability=True)\n",
    "\n",
    "model = Pipeline(steps=[('svc', svc)])\n",
    "\n",
    "\n",
    "param_grid = {'svc__C': st.randint(1,10000),\n",
    "              'svc__gamma': np.logspace(1, -7, 10)}\n",
    "\n",
    "grid = RandomizedSearchCV(model, param_grid,\n",
    "                          cv=cv, verbose=1, scoring=scoring,\n",
    "                         n_iter=n_iter, random_state=rstate)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "save(grid, \"SVCrbf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline and Principal Components Analysis and Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "svc = SVC(kernel= 'rbf',probability=True)\n",
    "\n",
    "model = Pipeline(steps=[('pca',pca),\n",
    "                        ('svc', svc)])\n",
    "\n",
    "\n",
    "param_grid = {'svc__C': st.randint(1,10000),\n",
    "              'svc__gamma': np.logspace(1, -7, 10),\n",
    "             'pca__n_components': st.randint(1,len(X.columns))}\n",
    "\n",
    "grid = RandomizedSearchCV(model, param_grid,\n",
    "                          cv=cv, verbose=1,\n",
    "                         n_iter=n_iter, random_state=rstate, scoring=scoring)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "save(grid, \"PCA_SVC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametric Generative Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = GaussianNB()\n",
    "\n",
    "score = cross_val_score(model, X_train, y_train, cv=cv, scoring=scoring)\n",
    "norm_save(model,score, \"Gaussian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = results.sort_values(by=[\"CV Mean\"], ascending=False)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Voting: Model Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Ensemble Voting\n",
    "not_proba_list = ('LinearSV','StochasticGradientDescent')\n",
    "not_proba =  results.query(\"Model in @not_proba_list\")\n",
    "hard_models = results # All Can Be\n",
    "prob_models = results.query(\"Model not in @not_proba_list\") # Not All\n",
    "# [x for x in results.Model if x not in not_proba_list]\n",
    "\n",
    "# Submission DataFrame for correlation purposes\n",
    "# Hard Output\n",
    "test_hard_pred_matrix = pd.DataFrame()\n",
    "train_hard_pred_matrix = pd.DataFrame()\n",
    "\n",
    "#Soft Output\n",
    "test_soft_pred_matrix = pd.DataFrame()\n",
    "train_soft_pred_matrix = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# None Probabilistic\n",
    "models = list(zip([ensemble_models[x] for x in not_proba.Model],\n",
    "                  not_proba.Model))\n",
    "clfs = []\n",
    "print('5-fold cross validation:\\n')\n",
    "for clf, label in models:\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=cv, scoring=scoring, verbose=0)\n",
    "    print(\"Train CV Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n",
    "    md = clf.fit(X_train, y_train)    \n",
    "    clfs.append(md)\n",
    "    print(\"Test Accuracy: %0.2f \\n\" % (metrics.accuracy_score(clf.predict(X_test), y_test)))\n",
    "    \n",
    "    # Model on Full Data\n",
    "    md = clf.fit(X,y)\n",
    "    submission = md.predict(test_df)\n",
    "    df = pd.DataFrame({'Company.Name':test_df.index, \n",
    "                           'Target':submission})\n",
    "    train_hard_pred_matrix = pd.concat((train_hard_pred_matrix, pd.DataFrame({label: md.predict(X)})), axis=1)\n",
    "    test_hard_pred_matrix = pd.concat((test_hard_pred_matrix, pd.DataFrame({label: submission})), axis=1)\n",
    "    df.to_csv(\"{}.csv\".format(label),header=True,index=False)\n",
    "\n",
    "del clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Only Probabilistic\n",
    "models = list(zip([ensemble_models[x] for x in prob_models.Model],\n",
    "                  prob_models.Model))\n",
    "plt.figure()\n",
    "\n",
    "print('5-fold cross validation:\\n')\n",
    "clfs = []\n",
    "#[ensemble_models[x] for x in prob_models.Model]\n",
    "for clf, label in models:\n",
    "    scores = cross_val_score(clf, X_train, y_train,cv=5, scoring=scoring, verbose=0)\n",
    "    print(\"Train CV Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n",
    "    md = clf.fit(X_train, y_train)\n",
    "    # Add to Roc Curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, md.predict_proba(X_test)[:,1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    print('ROC AUC: %0.2f' % roc_auc)\n",
    "    plt.plot(fpr, tpr, label='{} ROC curve (area = {:.2})'.format(label, roc_auc))\n",
    "    \n",
    "    clfs.append(md)\n",
    "    print(\"Test Accuracy: %0.2f \\n\" % (metrics.accuracy_score(clf.predict(X_test), y_test)))\n",
    "    \n",
    "    # Model on Full Data\n",
    "    md = clf.fit(X,y)\n",
    "    submission = md.predict(test_df)\n",
    "    df = pd.DataFrame({'Comapny.Name':test_df.index, \n",
    "                           'Target':submission})\n",
    "    train_hard_pred_matrix = pd.concat((train_hard_pred_matrix, pd.DataFrame({label: md.predict(X)})), axis=1)\n",
    "    test_hard_pred_matrix = pd.concat((test_hard_pred_matrix, pd.DataFrame({label: submission})), axis=1)\n",
    "\n",
    "    train_soft_pred_matrix = pd.concat((train_soft_pred_matrix, pd.DataFrame({label: md.predict(X)})), axis=1)\n",
    "    test_soft_pred_matrix = pd.concat((test_soft_pred_matrix, pd.DataFrame({label: md.predict_proba(test_df)[:,1]})), axis=1)\n",
    "    df.to_csv(\"{}.csv\".format(label),header=True,index=False)\n",
    "\n",
    "# Plot\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Receiver Operating Characteristic curve [ROC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Play with Weights\n",
    "plt.figure()\n",
    "voters = {}\n",
    "for x in [2,3,5,7,10]:\n",
    "    ECH = EnsembleVoteClassifier([ensemble_models.get(key) for key in hard_models.Model[:x]], voting='hard')\n",
    "    ECS = EnsembleVoteClassifier([ensemble_models.get(key) for key in prob_models.Model[:x]], voting='soft')\n",
    "    print('\\n{}-Voting Models: 5-fold cross validation:\\n'.format(x))\n",
    "    \n",
    "    for clf, label in zip([ECS, ECH], \n",
    "                          ['{}-VM-Ensemble Soft Voting'.format(x),\n",
    "                           '{}-VM-Ensemble Hard Voting'.format(x)]):\n",
    "        scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "        print(\"Train CV Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n",
    "        md = clf.fit(X_train, y_train)    \n",
    "        clfs.append(md)        \n",
    "        \n",
    "        Test_Score = metrics.accuracy_score(clf.predict(X_test), y_test)\n",
    "        print(\"Test Accuracy: %0.2f \" % Test_Score)\n",
    "        \n",
    "        CV_Score = scores.mean()\n",
    "        STDev = scores.std()\n",
    "        \n",
    "        global results\n",
    "        results = results.append({'Model': label,'Para': clf, 'CV Mean': CV_Score,\n",
    "                'Test_Score':Test_Score,'CV STDEV': STDev}, ignore_index=True)\n",
    "        voters[label] = clf\n",
    "        \n",
    "        # Model on Full Data\n",
    "        md = clf.fit(X,y)\n",
    "        submission = md.predict(test_df)\n",
    "        df = pd.DataFrame({'PassengerId':test_df.index,'Survived':submission})\n",
    "        df.to_csv(\"{}.csv\".format(label),header=True,index=False)\n",
    "        \n",
    "        if clf is ECH:\n",
    "            # Hard Correlation\n",
    "            train_hard_pred_matrix = pd.concat((train_hard_pred_matrix, pd.DataFrame({label: md.predict(X)})), axis=1)\n",
    "            test_hard_pred_matrix = pd.concat((test_hard_pred_matrix, pd.DataFrame({label: submission})), axis=1)\n",
    "        \n",
    "        elif clf is ECS:\n",
    "            # Add to Roc Curve\n",
    "            fpr, tpr, _ = roc_curve(y_test, md.predict_proba(X_test)[:,1])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            print('ROC AUC: %0.2f' % roc_auc)\n",
    "            plt.plot(fpr, tpr, label='{} ROC curve (area = {:.2})'.format(label, roc_auc))\n",
    "            # Soft Correlation\n",
    "            train_soft_pred_matrix = pd.concat((train_soft_pred_matrix, pd.DataFrame({label: md.predict(X)})), axis=1)\n",
    "            test_soft_pred_matrix = pd.concat((test_soft_pred_matrix, pd.DataFrame({label: md.predict_proba(test_df)[:,1]})), axis=1)\n",
    "        \n",
    "        \n",
    "# Plot\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Soft Model ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn Voter Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "voters.get('10-VM-Ensemble Hard Voting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xstack = X.copy()\n",
    "ystack = y.copy()\n",
    "X_trainstack = X_train.copy()\n",
    "X_teststack = X_test.copy()\n",
    "y_trainstack = y_train.copy()\n",
    "y_teststack = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "kfold = cross_validation.StratifiedKFold(y=y_trainstack, n_folds=5, random_state=rstate)\n",
    "num_trees = 10\n",
    "verbose = True # to print the progress\n",
    "\n",
    "clfs = [ensemble_models.get('KNN'),\n",
    "        ensemble_models.get('XGBstandard')]\n",
    "\n",
    "# Creating train and test sets for blending\n",
    "dataset_blend_train = np.zeros((X_trainstack.shape[0], len(clfs)))\n",
    "dataset_blend_test = np.zeros((X_teststack.shape[0], len(clfs)))\n",
    "dataset_blend_test_df = np.zeros((test_df.shape[0], len(clfs)))\n",
    "\n",
    "print('5-fold cross validation:')\n",
    "for i, clf in enumerate(clfs):   \n",
    "    scores = cross_validation.cross_val_score(clf, X_trainstack, y_trainstack, cv=kfold, scoring='accuracy')\n",
    "    print(\"##### Base Model %0.0f #####\" % i)\n",
    "    print(\"Train CV Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "    clf.fit(X_trainstack, y_trainstack)   \n",
    "    print(\"Train Accuracy: %0.2f \" % (metrics.accuracy_score(clf.predict(X_trainstack), y_trainstack)))\n",
    "    dataset_blend_train[:,i] = clf.predict_proba(X_trainstack)[:, 1]\n",
    "    dataset_blend_test[:,i] = clf.predict_proba(X_teststack)[:, 1]\n",
    "    dataset_blend_test_df[:,i] = clf.predict_proba(test_df)[:, 1]\n",
    "    print(\"Test Accuracy: %0.2f \\n\" % (metrics.accuracy_score(clf.predict(X_teststack), y_teststack)))    \n",
    "\n",
    "print(\"##### Meta Model #####\")\n",
    "clf = LogisticRegression()\n",
    "scores = cross_validation.cross_val_score(clf, dataset_blend_train, y_trainstack, cv=kfold, scoring=scoring)\n",
    "clf.fit(dataset_blend_train, y_trainstack)\n",
    "print(\"Train CV Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "print(\"Train Accuracy: %0.2f \" % (metrics.accuracy_score(clf.predict(dataset_blend_train), y_trainstack)))\n",
    "print(\"Test Accuracy: %0.2f \" % (metrics.accuracy_score(clf.predict(dataset_blend_test), y_teststack)))\n",
    "\n",
    "# Correlate Results\n",
    "#test_hard_pred_matrix = pd.concat((test_hard_pred_matrix, pd.DataFrame({label: clf.predict(dataset_blend_test_df)})), axis=1)\n",
    "#train_hard_pred_matrix = pd.concat((train_hard_pred_matrix, pd.DataFrame({label: model.predict(dataset_blend_train)})), axis=1)\n",
    "\n",
    "# Save\n",
    "pd.DataFrame({'Company.Name':test_df.index, \n",
    "    'Target':clf.predict(dataset_blend_test_df)}).to_csv(\n",
    "    \"{}.csv\".format(\"Stacked\"),header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = cross_val_score(clf, X, y, cv=cv, scoring=scoring)\n",
    "norm_save(clf, score, \"stacked\")\n",
    "eval_plot(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results.sort_values(by=[\"CV Mean\"], ascending=False, inplace=True)\n",
    "results.to_csv(\"results.csv\", index=False)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reinstate Data, since it was meddled with during Stacked Models\n",
    "X = train_df.drop([\"Target\"] , axis=1)\n",
    "y = train_df[\"Target\"]\n",
    "\n",
    "# Stratified Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape\n",
    "\n",
    "evalmodel = EnsembleVoteClassifier([ensemble_models.get(key) for key in prob_models.Model[:7]], voting='soft')\n",
    "evalmodel.fit(X_train, y_train)\n",
    "y_pred = evalmodel.predict(X_test)\n",
    "# Report\n",
    "print(\"\\n Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "confusion_matrix(y_test, y_pred)\n",
    "# Matrix\n",
    "print(\"\\n Matrix:\")\n",
    "skplt.metrics.plot_confusion_matrix(y_pred, y_test, normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "end = time.time()\n",
    "print(\"Notebook took %0.2f minutes to Run\"%((end - start)/60))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
